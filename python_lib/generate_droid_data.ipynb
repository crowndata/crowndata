{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install numpy\n",
    "# !pip3 install matplotlib\n",
    "# !pip3 install scipy\n",
    "# !pip3 install tensorflow_datasets\n",
    "# !pip3 install opencv-python\n",
    "# !pip3 install h5py\n",
    "# !pip3 install tensorflow\n",
    "# !pip3 install pandas\n",
    "# !pip3 install black\n",
    "# !pip3 install nbqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.enable_debug_mode()\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = tfds.builder_from_directory(builder_dir=\"../../data/droid_100/1.0.0/\")\n",
    "print(builder.info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data, step_size=1):\n",
    "    return zip(*[(data[i][:3], data[i][3:]) for i in range(0, len(data), step_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information(i):\n",
    "    return {\n",
    "        \"dataName\": \"robot_data_example\",\n",
    "        \"startTime\": \"2024-09-21T10:00:00Z\",\n",
    "        \"endTime\": \"2024-09-21T12:00:00Z\",\n",
    "        \"robotEmbodiment\": \"ALOHA\",\n",
    "        \"robotSerialNumber\": \"RS123456\",\n",
    "        \"videoSamplingRate\": 10,\n",
    "        \"armSamplingRate\": 50,\n",
    "        \"sensorSamplingRate\": 60,\n",
    "        \"operatorName\": \"John Doe\",\n",
    "        \"taskDescription\": \"Sample Task\",\n",
    "        \"subtaskDescription\": \"Subtask Description\",\n",
    "        \"taskState\": \"SUCCESS\",\n",
    "        \"subtaskState\": \"SUCCESS\",\n",
    "        \"dataLength\": 0,\n",
    "        \"durationInSeconds\": 0,\n",
    "        \"cameras\": [\n",
    "            \"exterior_image_1_left\",\n",
    "            \"exterior_image_2_left\",\n",
    "            \"wrist_image_left\",\n",
    "        ],\n",
    "        \"joints\": [\"cartesian_position\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds = tfds.load(\"droid_100\", data_dir=\"../../data\", split=\"train\")\n",
    "\n",
    "# Create an iterator\n",
    "ds_iter = iter(ds)\n",
    "\n",
    "for i in range(6):  # range(len(ds)):\n",
    "    data_folder = f\"../public/data/droid_{i:08d}\"\n",
    "    subprocess.call([\"mkdir\", \"-p\", data_folder])\n",
    "\n",
    "    # Save information\n",
    "    information = get_information(i)\n",
    "    information[\"dataName\"] = f\"droid_{i:08d}\"\n",
    "    information[\"taskDescription\"] = f\"pick up an item\"\n",
    "    information[\"subtaskDescription\"] = f\"reach out and pick up an item\"\n",
    "\n",
    "    subprocess.call([\"mkdir\", \"-p\", f\"{data_folder}/trajectories\"])\n",
    "    images = {}\n",
    "    trajectories = {}\n",
    "    cat_pose = []\n",
    "    # Save Trajectory\n",
    "    episode = next(ds_iter)\n",
    "    for step in episode[\"steps\"]:\n",
    "        for joint in information[\"joints\"]:\n",
    "            if joint not in trajectories.keys():\n",
    "                trajectories[joint] = []\n",
    "            trajectories[joint].append(step[\"action_dict\"][joint].numpy())\n",
    "        for c in information[\"cameras\"]:\n",
    "            if c not in images.keys():\n",
    "                images[c] = []\n",
    "\n",
    "            img = Image.fromarray(\n",
    "                np.concatenate((step[\"observation\"][c].numpy(),), axis=1)\n",
    "            )\n",
    "\n",
    "            # Get the current width and height of the image\n",
    "            width, height = img.size\n",
    "\n",
    "            # Calculate the new width while keeping the aspect ratio\n",
    "            aspect_ratio = width / height\n",
    "            new_height = 50\n",
    "            new_width = int(new_height * aspect_ratio)\n",
    "\n",
    "            # Resize the image\n",
    "            resized_image = img.resize(\n",
    "                (new_width, new_height), Image.Resampling.LANCZOS\n",
    "            )\n",
    "\n",
    "            # Save or show the resized image\n",
    "            images[c].append(resized_image)\n",
    "\n",
    "    for joint in information[\"joints\"]:\n",
    "        df = pd.DataFrame(\n",
    "            trajectories[joint], columns=[\"x\", \"y\", \"z\", \"roll\", \"pitch\", \"yaw\"]\n",
    "        )\n",
    "        df.to_json(\n",
    "            f\"{data_folder}/trajectories/{joint}__trajectory.json\",\n",
    "            orient=\"records\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    # Save Image\n",
    "    subprocess.call([\"mkdir\", \"-p\", f\"{data_folder}/images\"])\n",
    "    for c in information[\"cameras\"]:\n",
    "        for j, image in enumerate(images[c]):\n",
    "            # Save the image in WebP format\n",
    "            image.save(f\"{data_folder}/images/{c}__image_{j:08d}.webp\", format=\"WEBP\")\n",
    "\n",
    "        df_img = pd.DataFrame()\n",
    "        df_img[\"image\"] = [f\"{c}__image_{j:08d}.webp\" for j in range(len(df))]\n",
    "        df_img.to_json(\n",
    "            f\"{data_folder}/images/{c}__image.json\", orient=\"records\", index=False\n",
    "        )\n",
    "\n",
    "    # Define the directory containing the image sequence\n",
    "    output_video = f\"{data_folder}/video.mp4\"\n",
    "    c = information[\"cameras\"][-1]\n",
    "\n",
    "    frame_list_path = f\"frame_list.txt\"\n",
    "\n",
    "    # Create the frame list for every 100th image\n",
    "    with open(frame_list_path, \"w\") as f:\n",
    "        for i in range(0, len(df), 1):  # Adjust the range and step size as needed\n",
    "            f.write(f\"file '{data_folder}/images/{c}__image_{i:08d}.webp'\\n\")\n",
    "\n",
    "    ffmpeg_command = f\"ffmpeg -y -framerate 30 -i '{data_folder}/images/{c}__image_%08d.webp' -c:v libx264 -pix_fmt yuv420p '{data_folder}/video.mp4'\"\n",
    "    # ffmpeg_command = f\"ffmpeg -y -f concat -safe 0 -i {frame_list_path} -c:v libx264 -pix_fmt yuv420p -movflags +faststart '{data_folder}/video.mp4'\"\n",
    "    # ffmpeg_command = f\"ffmpeg -y -framerate 30 -i {frame_list_path} -c:v libx264 -pix_fmt yuv420p '{data_folder}/video.mp4'\"\n",
    "\n",
    "    subprocess.call(\n",
    "        ffmpeg_command,\n",
    "        shell=True,\n",
    "    )\n",
    "\n",
    "    # ffmpeg_command = f\"ffmpeg -y -f concat -safe 0 -i {frame_list_path} -c:v libx264 -pix_fmt yuv420p '{data_folder}/video.mp4'\"\n",
    "\n",
    "    # Assuming 'information' is the data you want to write to the JSON file\n",
    "    information[\"dataLength\"] = len(df)\n",
    "    information[\"durationInSeconds\"] = (\n",
    "        f'{len(df) / information[\"videoSamplingRate\"]:.2f}'\n",
    "    )\n",
    "    with open(f\"{data_folder}/information.json\", \"w\") as json_file:\n",
    "        json.dump(\n",
    "            information, json_file, indent=2\n",
    "        )  # The indent argument is optional, for pretty formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_format_action_dict(step):\n",
    "    formatted_action_dict = {}\n",
    "\n",
    "    for k, v in step.items():\n",
    "        try:\n",
    "            if isinstance(v, dict):\n",
    "                # If the value is a dictionary, recurse into it\n",
    "                formatted_action_dict[k] = plain_format_action_dict(v)\n",
    "            elif isinstance(v, tf.Tensor) and v.dtype == tf.string:\n",
    "                # If the value is a bytes (string in TensorFlow), decode it\n",
    "                formatted_action_dict[k] = v.numpy().decode(\"utf-8\")\n",
    "            elif isinstance(v, tf.Tensor):\n",
    "                # If the value is a Tensor, convert to a list\n",
    "                formatted_action_dict[k] = v.numpy().tolist()\n",
    "            else:\n",
    "                # Handle other data types directly (like int, float, bool)\n",
    "                formatted_action_dict[k] = v\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing key '{k}': {e}\")\n",
    "\n",
    "    return json.dumps(formatted_action_dict)\n",
    "\n",
    "\n",
    "# Assuming `ds` is a dataset object with a proper iterator\n",
    "ds_iter = iter(ds)\n",
    "data_list = []\n",
    "\n",
    "for i in range(1):  # Adjust as needed\n",
    "    episode = next(ds_iter)\n",
    "    step_data_list = []\n",
    "    for step in episode[\"steps\"]:\n",
    "        step_data_list.append(step)\n",
    "    new_step_data_list = []\n",
    "    for step in step_data_list:  # Adjust as needed\n",
    "        new_step_data_list.append(plain_format_action_dict(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
