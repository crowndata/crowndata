{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install numpy\n",
    "# !pip3 install matplotlib\n",
    "# !pip3 install scipy\n",
    "# !pip3 install tensorflow_datasets\n",
    "# !pip3 install opencv-python\n",
    "# !pip3 install h5py\n",
    "# !pip3 install tensorflow\n",
    "# !pip3 install pandas\n",
    "# !pip3 install black\n",
    "# !pip3 install nbqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.enable_debug_mode()\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeaturesDict({\n",
      "    'episode_metadata': FeaturesDict({\n",
      "        'file_path': string,\n",
      "        'recording_folderpath': string,\n",
      "    }),\n",
      "    'steps': Dataset({\n",
      "        'action': Tensor(shape=(7,), dtype=float64),\n",
      "        'action_dict': FeaturesDict({\n",
      "            'cartesian_position': Tensor(shape=(6,), dtype=float64),\n",
      "            'cartesian_velocity': Tensor(shape=(6,), dtype=float64),\n",
      "            'gripper_position': Tensor(shape=(1,), dtype=float64),\n",
      "            'gripper_velocity': Tensor(shape=(1,), dtype=float64),\n",
      "            'joint_position': Tensor(shape=(7,), dtype=float64),\n",
      "            'joint_velocity': Tensor(shape=(7,), dtype=float64),\n",
      "        }),\n",
      "        'discount': Scalar(shape=(), dtype=float32),\n",
      "        'is_first': bool,\n",
      "        'is_last': bool,\n",
      "        'is_terminal': bool,\n",
      "        'language_instruction': string,\n",
      "        'language_instruction_2': string,\n",
      "        'language_instruction_3': string,\n",
      "        'observation': FeaturesDict({\n",
      "            'cartesian_position': Tensor(shape=(6,), dtype=float64),\n",
      "            'exterior_image_1_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "            'exterior_image_2_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "            'gripper_position': Tensor(shape=(1,), dtype=float64),\n",
      "            'joint_position': Tensor(shape=(7,), dtype=float64),\n",
      "            'wrist_image_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "        }),\n",
      "        'reward': Scalar(shape=(), dtype=float32),\n",
      "    }),\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "builder = tfds.builder_from_directory(builder_dir=\"../../data/droid_100/1.0.0/\")\n",
    "print(builder.info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data, step_size=1):\n",
    "    return zip(*[(data[i][:3], data[i][3:]) for i in range(0, len(data), step_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information(i):\n",
    "    return {\n",
    "        \"dataFolderName\": \"robot_data_example\",\n",
    "        \"startTime\": \"2024-09-21T10:00:00Z\",\n",
    "        \"endTime\": \"2024-09-21T12:00:00Z\",\n",
    "        \"robotEmbodiment\": \"ALOHA\",\n",
    "        \"robotSerialNumber\": \"RS123456\",\n",
    "        \"videoSamplingRate\": 10,\n",
    "        \"armSamplingRate\": 50,\n",
    "        \"sensorSamplingRate\": 60,\n",
    "        \"operatorName\": \"John Doe\",\n",
    "        \"taskDescription\": \"Sample Task\",\n",
    "        \"subtaskDescription\": \"Subtask Description\",\n",
    "        \"taskState\": \"SUCCESS\",\n",
    "        \"subtaskState\": \"SUCCESS\",\n",
    "        \"dataLength\": 0,\n",
    "        \"durationInSeconds\": 0,\n",
    "        \"cameras\": [\n",
    "            \"exterior_image_1_left\",\n",
    "            \"exterior_image_2_left\",\n",
    "            \"wrist_image_left\",\n",
    "        ],\n",
    "        \"joints\": [\"cartesian_position\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.0.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, concat, from 'frame_list.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: webp, yuv420p(tv, bt470bg/unknown/unknown), 177x100, 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (webp (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[concat @ 0x15a7066d0] DTS -230584300921369 < 0 out of order\n",
      "DTS -230584300921369, next:40000 st:0 invalid dropping\n",
      "PTS -230584300921369, next:40000 invalid dropping st:0\n",
      "[concat @ 0x15a7066d0] Impossible to open '../public/data/droid_00000000/images/wrist_image_left__image_00000200.webp'\n",
      "[in#0/concat @ 0x15a706480] Error during demuxing: No such file or directory\n",
      "[libx264 @ 0x15a709730] width not divisible by 2 (177x100)\n",
      "[vost#0:0/libx264 @ 0x15a709300] Error while opening encoder - maybe incorrect parameters such as bit_rate, rate, width or height.\n",
      "[vf#0:0 @ 0x15a70a240] Error sending frames to consumers: Generic error in an external library\n",
      "[vf#0:0 @ 0x15a70a240] Task finished with error code: -542398533 (Generic error in an external library)\n",
      "[vf#0:0 @ 0x15a70a240] Terminating thread with return code -542398533 (Generic error in an external library)\n",
      "[vost#0:0/libx264 @ 0x15a709300] Could not open encoder before EOF\n",
      "[vost#0:0/libx264 @ 0x15a709300] Task finished with error code: -22 (Invalid argument)\n",
      "[vost#0:0/libx264 @ 0x15a709300] Terminating thread with return code -22 (Invalid argument)\n",
      "[out#0/mp4 @ 0x15a708280] Nothing was written into output file, because at least one of its streams received no packets.\n",
      "frame=    0 fps=0.0 q=0.0 Lsize=       0KiB time=N/A bitrate=N/A speed=N/A    \n",
      "Conversion failed!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "ds = tfds.load(\"droid_100\", data_dir=\"../../data\", split=\"train\")\n",
    "\n",
    "# Create an iterator\n",
    "ds_iter = iter(ds)\n",
    "\n",
    "for i in range(6):  # range(len(ds)):\n",
    "    data_folder = f\"../public/data/droid_{i:08d}\"\n",
    "    subprocess.call([\"mkdir\", \"-p\", data_folder])\n",
    "\n",
    "    # Save information\n",
    "    information = get_information(i)\n",
    "    information[\"dataFolderName\"] = f\"droid_{i:08d}\"\n",
    "    information[\"taskDescription\"] = f\"pick up an item\"\n",
    "    information[\"subtaskDescription\"] = f\"reach out and pick up an item\"\n",
    "\n",
    "    subprocess.call([\"mkdir\", \"-p\", f\"{data_folder}/trajectories\"])\n",
    "    images = {}\n",
    "    trajectories = {}\n",
    "    cat_pose = []\n",
    "    # Save Trajectory\n",
    "    episode = next(ds_iter)\n",
    "    for step in episode[\"steps\"]:\n",
    "        for joint in information[\"joints\"]:\n",
    "            if joint not in trajectories.keys():\n",
    "                trajectories[joint] = []\n",
    "            trajectories[joint].append(step[\"action_dict\"][joint].numpy())\n",
    "        for c in information[\"cameras\"]:\n",
    "            if c not in images.keys():\n",
    "                images[c] = []\n",
    "\n",
    "            img = Image.fromarray(\n",
    "                np.concatenate((step[\"observation\"][c].numpy(),), axis=1)\n",
    "            )\n",
    "\n",
    "            # Get the current width and height of the image\n",
    "            width, height = img.size\n",
    "\n",
    "            # Calculate the new width while keeping the aspect ratio\n",
    "            aspect_ratio = width / height\n",
    "            new_height = 100\n",
    "            new_width = int(new_height * aspect_ratio)\n",
    "\n",
    "            # Resize the image\n",
    "            resized_image = img.resize(\n",
    "                (new_width, new_height), Image.Resampling.LANCZOS\n",
    "            )\n",
    "\n",
    "            # Save or show the resized image\n",
    "            images[c].append(resized_image)\n",
    "\n",
    "    for joint in information[\"joints\"]:\n",
    "        df = pd.DataFrame(\n",
    "            trajectories[joint], columns=[\"x\", \"y\", \"z\", \"roll\", \"pitch\", \"yaw\"]\n",
    "        )\n",
    "        df.to_json(\n",
    "            f\"{data_folder}/trajectories/{joint}__trajectory.json\",\n",
    "            orient=\"records\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    # Save Image\n",
    "    subprocess.call([\"mkdir\", \"-p\", f\"{data_folder}/images\"])\n",
    "    for c in information[\"cameras\"]:\n",
    "        for j, image in enumerate(images[c]):\n",
    "            # Save the image in WebP format\n",
    "            image.save(\n",
    "                f\"{data_folder}/images/{c}__image_{j:08d}.webp\",\n",
    "                format=\"WEBP\",\n",
    "                quality=15,\n",
    "                optimize=True,\n",
    "            )\n",
    "        df_img = pd.DataFrame()\n",
    "        df_img[\"image\"] = [f\"{c}__image_{j:08d}.webp\" for j in range(len(df))]\n",
    "        df_img.to_json(\n",
    "            f\"{data_folder}/images/{c}__image.json\", orient=\"records\", index=False\n",
    "        )\n",
    "\n",
    "    # Define the directory containing the image sequence\n",
    "    output_video = f\"{data_folder}/video.mp4\"\n",
    "    c = information[\"cameras\"][-1]\n",
    "\n",
    "    frame_list_path = f\"frame_list.txt\"\n",
    "\n",
    "    # Create the frame list for every 100th image\n",
    "    with open(frame_list_path, \"w\") as f:\n",
    "        for i in range(0, 1000, 100):  # Adjust the range and step size as needed\n",
    "            f.write(f\"file '{data_folder}/images/{c}__image_{i:08d}.webp'\\n\")\n",
    "\n",
    "    ffmpeg_command = f\"ffmpeg -y -f concat -safe 0 -i {frame_list_path} -c:v libx264 -pix_fmt yuv420p '{data_folder}/video.mp4'\"\n",
    "\n",
    "    subprocess.call(\n",
    "        ffmpeg_command,\n",
    "        shell=True,\n",
    "    )\n",
    "\n",
    "    # ffmpeg_command = f\"ffmpeg -y -f concat -safe 0 -i {frame_list_path} -c:v libx264 -pix_fmt yuv420p '{data_folder}/video.mp4'\"\n",
    "\n",
    "    # Assuming 'information' is the data you want to write to the JSON file\n",
    "    information[\"dataLength\"] = len(df)\n",
    "    information[\"durationInSeconds\"] = (\n",
    "        f'{len(df) / information[\"videoSamplingRate\"]:.2f}'\n",
    "    )\n",
    "    with open(f\"{data_folder}/information.json\", \"w\") as json_file:\n",
    "        json.dump(\n",
    "            information, json_file, indent=2\n",
    "        )  # The indent argument is optional, for pretty formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_format_action_dict(step):\n",
    "    formatted_action_dict = {}\n",
    "\n",
    "    for k, v in step.items():\n",
    "        try:\n",
    "            if isinstance(v, dict):\n",
    "                # If the value is a dictionary, recurse into it\n",
    "                formatted_action_dict[k] = plain_format_action_dict(v)\n",
    "            elif isinstance(v, tf.Tensor) and v.dtype == tf.string:\n",
    "                # If the value is a bytes (string in TensorFlow), decode it\n",
    "                formatted_action_dict[k] = v.numpy().decode(\"utf-8\")\n",
    "            elif isinstance(v, tf.Tensor):\n",
    "                # If the value is a Tensor, convert to a list\n",
    "                formatted_action_dict[k] = v.numpy().tolist()\n",
    "            else:\n",
    "                # Handle other data types directly (like int, float, bool)\n",
    "                formatted_action_dict[k] = v\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing key '{k}': {e}\")\n",
    "\n",
    "    return json.dumps(formatted_action_dict)\n",
    "\n",
    "\n",
    "# Assuming `ds` is a dataset object with a proper iterator\n",
    "ds_iter = iter(ds)\n",
    "data_list = []\n",
    "\n",
    "for i in range(1):  # Adjust as needed\n",
    "    episode = next(ds_iter)\n",
    "    step_data_list = []\n",
    "    for step in episode[\"steps\"]:\n",
    "        step_data_list.append(step)\n",
    "    new_step_data_list = []\n",
    "    for step in step_data_list:  # Adjust as needed\n",
    "        new_step_data_list.append(plain_format_action_dict(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
